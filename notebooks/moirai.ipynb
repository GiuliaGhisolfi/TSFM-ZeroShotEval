{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: Running Foundation Model Moirai on gift-eval benchmark\n",
    "\n",
    "This notebook shows how to run the Foundation Model Moirai on the gift-eval benchmark.\n",
    "\n",
    "Make sure you download the gift-eval benchmark and set the `GIFT-EVAL` environment variable correctly before running this notebook.\n",
    "\n",
    "We will use the `Dataset` class to load the data and run the model. If you have not already please check out the [dataset.ipynb](./dataset.ipynb) notebook to learn more about the `Dataset` class. We are going to just run the model on two datasets for brevity. But feel free to run on any dataset by changing the `short_datasets` and `med_long_datasets` variables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_GIFT_EVAL = [\n",
    "    \"bitbrains_fast_storage\",\n",
    "    \"bitbrains_rnd\",\n",
    "    \"bizitobs_application\",\n",
    "    \"bizitobs_l2c\",\n",
    "    \"bizitobs_service\",\n",
    "\n",
    "    \"jena_weather\",\n",
    "    \n",
    "    \"solar\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# short_datasets = \"m4_yearly m4_quarterly m4_monthly m4_weekly m4_daily m4_hourly \n",
    "# electricity/15T electricity/H electricity/D electricity/W \n",
    "# solar/10T solar/H solar/D solar/W \n",
    "# hospital covid_deaths us_births/D us_births/M us_births/W \n",
    "# saugeenday/D saugeenday/M saugeenday/W \n",
    "# temperature_rain_with_missing kdd_cup_2018_with_missing/H \n",
    "# kdd_cup_2018_with_missing/D \n",
    "# car_parts_with_missing restaurant hierarchical_sales/D hierarchical_sales/W \n",
    "# LOOP_SEATTLE/5T LOOP_SEATTLE/H LOOP_SEATTLE/D SZ_TAXI/15T SZ_TAXI/H \n",
    "# M_DENSE/H M_DENSE/D ett1/15T ett1/H ett1/D ett1/W ett2/15T ett2/H ett2/D ett2/W \n",
    "# jena_weather/10T jena_weather/H jena_weather/D \n",
    "# bitbrains_fast_storage/5T bitbrains_fast_storage/H bitbrains_rnd/5T bitbrains_rnd/H bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "short_datasets = \"solar/10T solar/H solar/D solar/W jena_weather/10T jena_weather/H jena_weather/D \" \\\n",
    "\"bitbrains_fast_storage/5T bitbrains_fast_storage/H bitbrains_rnd/5T bitbrains_rnd/H bizitobs_application \" \\\n",
    "\"bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "\n",
    "# med_long_datasets = \"electricity/15T electricity/H \n",
    "# solar/10T solar/H \n",
    "# kdd_cup_2018_with_missing/H LOOP_SEATTLE/5T LOOP_SEATTLE/H SZ_TAXI/15T M_DENSE/H ett1/15T ett1/H ett2/15T ett2/H \n",
    "# jena_weather/10T jena_weather/H \n",
    "# bitbrains_fast_storage/5T bitbrains_rnd/5T bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "med_long_datasets = \"solar/10T solar/H jena_weather/10T jena_weather/H \" \\\n",
    "\"bitbrains_fast_storage/5T bitbrains_rnd/5T bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "\n",
    "# Get union of short and med_long datasets\n",
    "all_datasets = list(set(short_datasets.split() + med_long_datasets.split()))\n",
    "\n",
    "dataset_properties_map = json.load(open(\"data/dataset_properties.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.ev.metrics import (\n",
    "    MSE,\n",
    "    MAE,\n",
    "    MASE,\n",
    "    MAPE,\n",
    "    SMAPE,\n",
    "    MSIS,\n",
    "    RMSE,\n",
    "    NRMSE,\n",
    "    ND,\n",
    "    MeanWeightedSumQuantileLoss,\n",
    ")\n",
    "\n",
    "# Instantiate the metrics\n",
    "metrics = [\n",
    "    MSE(forecast_type=\"mean\"),\n",
    "    MSE(forecast_type=0.5),\n",
    "    MAE(),\n",
    "    MASE(),\n",
    "    MAPE(),\n",
    "    SMAPE(),\n",
    "    MSIS(),\n",
    "    RMSE(),\n",
    "    NRMSE(),\n",
    "    ND(),\n",
    "    MeanWeightedSumQuantileLoss(\n",
    "        quantile_levels=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moirai Predictor\n",
    "We first install moirai via  \n",
    "1. `pip install uni2ts`. \n",
    "\n",
    "Its predictor has already inherited `gluonts.torch.PyTorchPredictor` which is compatible with the `gluonts` evaluation pipeline. Note that there is a dependency conflict that `uni2ts` uses `gluonts~=0.14.3` for its evaluation while `gift_eval` requires `gluonts~=0.15.1`. \n",
    "Here, we need to reinstall it via \n",
    "\n",
    "2. `pip install gluonts==0.15.1`\n",
    "\n",
    "We then load the model with initial hyperparameters, like `prediction_length`, `context_length`, `patch_size`, `num_samples`, etc. You can find more details about these hyperparameters from <https://github.com/SalesforceAIResearch/uni2ts/blob/main/example/moirai_forecast_pandas.ipynb>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\giuli\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\giuli\\AppData\\Local\\Temp\\ipykernel_13356\\4201151771.py\", line 1, in <module>\n",
      "    from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
      "  File \"c:\\Documenti\\VS_Code\\tesi\\TSFM-ZeroShotEval\\uni2ts\\model\\moirai\\__init__.py\", line 16, in <module>\n",
      "    from .finetune import MoiraiFinetune\n",
      "  File \"c:\\Documenti\\VS_Code\\tesi\\TSFM-ZeroShotEval\\uni2ts\\model\\moirai\\finetune.py\", line 21, in <module>\n",
      "    import lightning as L\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\lightning\\__init__.py\", line 18, in <module>\n",
      "    from lightning.fabric.fabric import Fabric  # noqa: E402\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\lightning\\fabric\\__init__.py\", line 29, in <module>\n",
      "    from lightning.fabric.fabric import Fabric  # noqa: E402\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\lightning\\fabric\\fabric.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\giuli\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\giuli\\AppData\\Local\\Temp\\ipykernel_13356\\4201151771.py\", line 1, in <module>\n",
      "    from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
      "  File \"c:\\Documenti\\VS_Code\\tesi\\TSFM-ZeroShotEval\\uni2ts\\model\\moirai\\__init__.py\", line 16, in <module>\n",
      "    from .finetune import MoiraiFinetune\n",
      "  File \"c:\\Documenti\\VS_Code\\tesi\\TSFM-ZeroShotEval\\uni2ts\\model\\moirai\\finetune.py\", line 35, in <module>\n",
      "    from uni2ts.transform import (AddObservedMask, AddTimeIndex, AddVariateIndex,\n",
      "  File \"c:\\Documenti\\VS_Code\\tesi\\TSFM-ZeroShotEval\\uni2ts\\transform\\__init__.py\", line 22, in <module>\n",
      "    from .patch import (\n",
      "  File \"c:\\Documenti\\VS_Code\\tesi\\TSFM-ZeroShotEval\\uni2ts\\transform\\patch.py\", line 22, in <module>\n",
      "    import pandas as pd\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "\n",
    "model = MoiraiForecast(\n",
    "    module=MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.0-R-small\"),\n",
    "    prediction_length=1,\n",
    "    context_length=4000,\n",
    "    patch_size=32,\n",
    "    num_samples=100,\n",
    "    target_dim=1,\n",
    "    feat_dynamic_real_dim=0,\n",
    "    past_feat_dynamic_real_dim=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now that we have our predictor class, we can use it to predict on the gift-eval benchmark datasets. We will use the `evaluate_model` function to evaluate the model. This function is a helper function to evaluate the model on the test data and return the results in a dictionary. We are going to follow the naming conventions explained in the [README](../README.md) file to store the results in a csv file called `all_results.csv` under the `results/moirai_small` folder.\n",
    "\n",
    "The first column in the csv file is the dataset config name which is a combination of the dataset name, frequency and the term:\n",
    "\n",
    "```python\n",
    "f\"{dataset_name}/{freq}/{term}\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.model import evaluate_model\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from gluonts.time_feature import get_seasonality\n",
    "from gift_eval.data import Dataset\n",
    "\n",
    "# Iterate over all available datasets\n",
    "\n",
    "output_dir = \"results/moirai_small\"\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "pretty_names = {\n",
    "    \"saugeenday\": \"saugeen\",\n",
    "    \"temperature_rain_with_missing\": \"temperature_rain\",\n",
    "    \"kdd_cup_2018_with_missing\": \"kdd_cup_2018\",\n",
    "    \"car_parts_with_missing\": \"car_parts\",\n",
    "}\n",
    "\n",
    "# Define the path for the CSV file\n",
    "csv_file_path = os.path.join(output_dir, \"all_results.csv\")\n",
    "\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writerow(\n",
    "        [\n",
    "            \"dataset\",\n",
    "            \"model\",\n",
    "            \"eval_metrics/MSE[mean]\",\n",
    "            \"eval_metrics/MSE[0.5]\",\n",
    "            \"eval_metrics/MAE[0.5]\",\n",
    "            \"eval_metrics/MASE[0.5]\",\n",
    "            \"eval_metrics/MAPE[0.5]\",\n",
    "            \"eval_metrics/sMAPE[0.5]\",\n",
    "            \"eval_metrics/MSIS\",\n",
    "            \"eval_metrics/RMSE[mean]\",\n",
    "            \"eval_metrics/NRMSE[mean]\",\n",
    "            \"eval_metrics/ND[0.5]\",\n",
    "            \"eval_metrics/mean_weighted_sum_quantile_loss\",\n",
    "            \"domain\",\n",
    "            \"num_variates\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bitbrains_fast_storage/5T',\n",
       " 'bitbrains_rnd/H',\n",
       " 'jena_weather/H',\n",
       " 'solar/W',\n",
       " 'jena_weather/10T',\n",
       " 'solar/H',\n",
       " 'bitbrains_fast_storage/H',\n",
       " 'bizitobs_l2c/5T',\n",
       " 'bizitobs_l2c/H',\n",
       " 'solar/10T',\n",
       " 'bitbrains_rnd/5T',\n",
       " 'jena_weather/D',\n",
       " 'bizitobs_application',\n",
       " 'solar/D',\n",
       " 'bizitobs_service']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: bitbrains_fast_storage/5T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documenti\\VS_Code\\tesi\\TSFM-ZeroShotEval\\gift_eval\\data.py:143: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  freq = norm_freq_str(to_offset(self.freq).name)\n",
      "c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\gluonts\\time_feature\\seasonality.py:47: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  offset = pd.tseries.frequencies.to_offset(freq)\n",
      "c:\\Users\\giuli\\anaconda3\\lib\\site-packages\\gluonts\\dataset\\common.py:263: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  return pd.Period(val, freq)\n",
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "for ds_name in all_datasets:\n",
    "    ds_key = ds_name.split(\"/\")[0]\n",
    "    print(f\"Processing dataset: {ds_name}\")\n",
    "    terms = [\"short\", \"medium\", \"long\"]\n",
    "    for term in terms:\n",
    "        if (\n",
    "            term == \"medium\" or term == \"long\"\n",
    "        ) and ds_name not in med_long_datasets.split():\n",
    "            continue\n",
    "\n",
    "        if \"/\" in ds_name:\n",
    "            ds_key = ds_name.split(\"/\")[0]\n",
    "            ds_freq = ds_name.split(\"/\")[1]\n",
    "            ds_key = ds_key.lower()\n",
    "            ds_key = pretty_names.get(ds_key, ds_key)\n",
    "        else:\n",
    "            ds_key = ds_name.lower()\n",
    "            ds_key = pretty_names.get(ds_key, ds_key)\n",
    "            ds_freq = dataset_properties_map[ds_key][\"frequency\"]\n",
    "\n",
    "        ds_config = f\"{ds_key}/{ds_freq}/{term}\"\n",
    "\n",
    "        # Initialize the dataset, since Moirai support multivariate time series forecast, it does not require\n",
    "        # to convert the original data into univariate\n",
    "        # to_univariate = False if Dataset(name=ds_name, term=term,to_univariate=False).target_dim == 1 else True\n",
    "        to_univariate = False\n",
    "        dataset = Dataset(name=ds_name, term=term, to_univariate=to_univariate)\n",
    "\n",
    "        # set the Moirai hyperparameter according to each dataset, then create the predictor\n",
    "        model.hparams.prediction_length = dataset.prediction_length\n",
    "        model.hparams.target_dim = dataset.target_dim\n",
    "        model.hparams.past_feat_dynamic_real_dim = dataset.past_feat_dynamic_real_dim\n",
    "\n",
    "        predictor = model.create_predictor(batch_size=512)\n",
    "\n",
    "        season_length = get_seasonality(dataset.freq)\n",
    "\n",
    "        res = evaluate_model(\n",
    "            predictor,\n",
    "            test_data=dataset.test_data,\n",
    "            metrics=metrics,\n",
    "            batch_size=512,\n",
    "            axis=None,\n",
    "            mask_invalid_label=True,\n",
    "            allow_nan_forecast=False,\n",
    "            seasonality=season_length,\n",
    "        )\n",
    "\n",
    "        # Append the results to the CSV file\n",
    "        with open(csv_file_path, \"a\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    ds_config,\n",
    "                    \"moirai_small\",\n",
    "                    res[\"MSE[mean]\"][0],\n",
    "                    res[\"MSE[0.5]\"][0],\n",
    "                    res[\"MAE[0.5]\"][0],\n",
    "                    res[\"MASE[0.5]\"][0],\n",
    "                    res[\"MAPE[0.5]\"][0],\n",
    "                    res[\"sMAPE[0.5]\"][0],\n",
    "                    res[\"MSIS\"][0],\n",
    "                    res[\"RMSE[mean]\"][0],\n",
    "                    res[\"NRMSE[mean]\"][0],\n",
    "                    res[\"ND[0.5]\"][0],\n",
    "                    res[\"mean_weighted_sum_quantile_loss\"][0],\n",
    "                    dataset_properties_map[ds_key][\"domain\"],\n",
    "                    dataset_properties_map[ds_key][\"num_variates\"],\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        print(f\"Results for {ds_name} have been written to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Running the above cell will generate a csv file called `all_results.csv` under the `results/moirai_small` folder containing the results for the Moirai model on the gift-eval benchmark. The csv file will look like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>eval_metrics/MSE[mean]</th>\n",
       "      <th>eval_metrics/MSE[0.5]</th>\n",
       "      <th>eval_metrics/MAE[0.5]</th>\n",
       "      <th>eval_metrics/MASE[0.5]</th>\n",
       "      <th>eval_metrics/MAPE[0.5]</th>\n",
       "      <th>eval_metrics/sMAPE[0.5]</th>\n",
       "      <th>eval_metrics/MSIS</th>\n",
       "      <th>eval_metrics/RMSE[mean]</th>\n",
       "      <th>eval_metrics/NRMSE[mean]</th>\n",
       "      <th>eval_metrics/ND[0.5]</th>\n",
       "      <th>eval_metrics/mean_weighted_sum_quantile_loss</th>\n",
       "      <th>domain</th>\n",
       "      <th>num_variates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m4_weekly/W/short</td>\n",
       "      <td>moirai_small</td>\n",
       "      <td>437099.622027</td>\n",
       "      <td>453879.826870</td>\n",
       "      <td>338.839136</td>\n",
       "      <td>2.920490</td>\n",
       "      <td>0.085097</td>\n",
       "      <td>0.086998</td>\n",
       "      <td>23.585943</td>\n",
       "      <td>661.135101</td>\n",
       "      <td>0.120449</td>\n",
       "      <td>0.061731</td>\n",
       "      <td>0.049446</td>\n",
       "      <td>Econ/Fin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bizitobs_l2c/H/short</td>\n",
       "      <td>moirai_small</td>\n",
       "      <td>206.179207</td>\n",
       "      <td>263.056114</td>\n",
       "      <td>10.446510</td>\n",
       "      <td>0.991831</td>\n",
       "      <td>0.710535</td>\n",
       "      <td>0.967966</td>\n",
       "      <td>6.907090</td>\n",
       "      <td>14.358942</td>\n",
       "      <td>0.773984</td>\n",
       "      <td>0.563094</td>\n",
       "      <td>0.441195</td>\n",
       "      <td>Web/CloudOps</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bizitobs_l2c/H/medium</td>\n",
       "      <td>moirai_small</td>\n",
       "      <td>247.660733</td>\n",
       "      <td>333.526153</td>\n",
       "      <td>12.879722</td>\n",
       "      <td>1.224496</td>\n",
       "      <td>0.948535</td>\n",
       "      <td>1.186153</td>\n",
       "      <td>6.980682</td>\n",
       "      <td>15.737240</td>\n",
       "      <td>0.952914</td>\n",
       "      <td>0.779887</td>\n",
       "      <td>0.573954</td>\n",
       "      <td>Web/CloudOps</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bizitobs_l2c/H/long</td>\n",
       "      <td>moirai_small</td>\n",
       "      <td>267.319444</td>\n",
       "      <td>353.404489</td>\n",
       "      <td>13.129816</td>\n",
       "      <td>1.275734</td>\n",
       "      <td>0.932632</td>\n",
       "      <td>1.224417</td>\n",
       "      <td>6.492169</td>\n",
       "      <td>16.349907</td>\n",
       "      <td>0.998699</td>\n",
       "      <td>0.802007</td>\n",
       "      <td>0.605737</td>\n",
       "      <td>Web/CloudOps</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dataset         model  eval_metrics/MSE[mean]   \n",
       "0      m4_weekly/W/short  moirai_small           437099.622027  \\\n",
       "1   bizitobs_l2c/H/short  moirai_small              206.179207   \n",
       "2  bizitobs_l2c/H/medium  moirai_small              247.660733   \n",
       "3    bizitobs_l2c/H/long  moirai_small              267.319444   \n",
       "\n",
       "   eval_metrics/MSE[0.5]  eval_metrics/MAE[0.5]  eval_metrics/MASE[0.5]   \n",
       "0          453879.826870             338.839136                2.920490  \\\n",
       "1             263.056114              10.446510                0.991831   \n",
       "2             333.526153              12.879722                1.224496   \n",
       "3             353.404489              13.129816                1.275734   \n",
       "\n",
       "   eval_metrics/MAPE[0.5]  eval_metrics/sMAPE[0.5]  eval_metrics/MSIS   \n",
       "0                0.085097                 0.086998          23.585943  \\\n",
       "1                0.710535                 0.967966           6.907090   \n",
       "2                0.948535                 1.186153           6.980682   \n",
       "3                0.932632                 1.224417           6.492169   \n",
       "\n",
       "   eval_metrics/RMSE[mean]  eval_metrics/NRMSE[mean]  eval_metrics/ND[0.5]   \n",
       "0               661.135101                  0.120449              0.061731  \\\n",
       "1                14.358942                  0.773984              0.563094   \n",
       "2                15.737240                  0.952914              0.779887   \n",
       "3                16.349907                  0.998699              0.802007   \n",
       "\n",
       "   eval_metrics/mean_weighted_sum_quantile_loss        domain  num_variates  \n",
       "0                                      0.049446      Econ/Fin             1  \n",
       "1                                      0.441195  Web/CloudOps             7  \n",
       "2                                      0.573954  Web/CloudOps             7  \n",
       "3                                      0.605737  Web/CloudOps             7  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"results/moirai_small/all_results.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mcurrent_device()))\n",
      "File \u001b[1;32mc:\\Users\\giuli\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:787\u001b[0m, in \u001b[0;36mcurrent_device\u001b[1;34m()\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m    786\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[1;32mc:\\Users\\giuli\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[0;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[0;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

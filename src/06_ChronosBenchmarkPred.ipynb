{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1841c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gluonts\n",
    "!pip install --upgrade datasets\n",
    "!pip install utilsforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18cff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/GiuliaGhisolfi/TSFM-ZeroShotEval\n",
    "%cd TSFM-ZeroShotEval/src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eba777",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af26ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/chronos_data_proprieties.json\") as f:\n",
    "    dataset_properties_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf66515",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CHRONOS = [\"exchange_rate\", \"ercot\", \"dominick\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcef99e",
   "metadata": {},
   "source": [
    "### Results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b968571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = \"results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the path for the CSV file\n",
    "csv_file_path = os.path.join(output_dir, \"chronos_data_results.csv\")\n",
    "\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writerow(\n",
    "        [\n",
    "            \"dataset\",\n",
    "            \"model\",\n",
    "            \"eval_metrics/MSE[mean]\",\n",
    "            \"eval_metrics/MSE[0.5]\",\n",
    "            \"eval_metrics/MAE[0.5]\",\n",
    "            \"eval_metrics/MASE[0.5]\",\n",
    "            \"eval_metrics/MAPE[0.5]\",\n",
    "            \"eval_metrics/sMAPE[0.5]\",\n",
    "            \"eval_metrics/MSIS\",\n",
    "            \"eval_metrics/RMSE[mean]\",\n",
    "            \"eval_metrics/NRMSE[mean]\",\n",
    "            \"eval_metrics/ND[0.5]\",\n",
    "            \"eval_metrics/mean_weighted_sum_quantile_loss\",\n",
    "            \"domain\",\n",
    "            \"num_variates\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f589b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec22642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.ev.metrics import (\n",
    "    MSE,\n",
    "    MAE,\n",
    "    MASE,\n",
    "    MAPE,\n",
    "    SMAPE,\n",
    "    MSIS,\n",
    "    RMSE,\n",
    "    NRMSE,\n",
    "    ND,\n",
    "    MeanWeightedSumQuantileLoss,\n",
    ")\n",
    "\n",
    "# Instantiate the metrics\n",
    "metrics = [\n",
    "    MSE(forecast_type=\"mean\"),\n",
    "    MSE(forecast_type=0.5),\n",
    "    MAE(),\n",
    "    MASE(),\n",
    "    MAPE(),\n",
    "    SMAPE(),\n",
    "    MSIS(),\n",
    "    RMSE(),\n",
    "    NRMSE(),\n",
    "    ND(),\n",
    "    MeanWeightedSumQuantileLoss(\n",
    "        quantile_levels=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f18dcf",
   "metadata": {},
   "source": [
    "### Chronos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2e86c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"chronos_bolt_small\" # TODO: change to \"chronos_t5_base\" for the original Chronos model\n",
    "\n",
    "model_path=\"amazon/chronos-bolt-small\",\n",
    "# TODO: use \"amazon/chronos-t5-base\" for the corresponding original Chronos model\n",
    "# \"amazon/chronos-bolt-tiny\", \"amazon/chronos-bolt-mini\", \"amazon/chronos-bolt-small\", \"amazon/chronos-bolt-base\",\n",
    "# \"amazon/chronos-t5-tiny\", \"amazon/chronos-t5-mini\", \"amazon/chronos-t5-small\",\n",
    "# \"amazon/chronos-t5-base\", \"amazon/chronos-t5-large\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5befed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.chronos_predictor import ChronosPredictor\n",
    "from gluonts.model import evaluate_model\n",
    "from gluonts.time_feature import get_seasonality\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "for ds_name in DATASET_CHRONOS:\n",
    "        print(f\"Processing dataset: {ds_name}\")\n",
    "        terms = [\"short\", \"medium\", \"long\"]\n",
    "        for term in terms:\n",
    "            ds_config = f\"{ds_name}/{term}\"\n",
    "\n",
    "            dataset = pd.read_parquet(\"data/chronos_benchmark/exchange_rate.arrow\")\n",
    "            season_length = get_seasonality(dataset_properties_map[ds_name][\"freq\"])\n",
    "            prediction_length = dataset_properties_map[ds_name][\"prediction_length\"]\n",
    "\n",
    "            print(f\"Dataset size: {len(dataset.test_data)}\")\n",
    "            model = ChronosPredictor(\n",
    "                model_path=model_path,\n",
    "                num_samples=20,\n",
    "                prediction_length=dataset.prediction_length,\n",
    "                # Change device_map to \"cpu\" to run on CPU or \"cuda\" to run on GPU\n",
    "                device_map=\"cpu\",\n",
    "            )\n",
    "            predictor = model.create_predictor(batch_size=32)\n",
    "\n",
    "            res = evaluate_model(\n",
    "                predictor,\n",
    "                test_data=dataset.test_data,\n",
    "                metrics=metrics,\n",
    "                batch_size=512,\n",
    "                axis=None,\n",
    "                mask_invalid_label=True,\n",
    "                allow_nan_forecast=False,\n",
    "                seasonality=season_length,\n",
    "            )\n",
    "\n",
    "            # Append the results to the CSV file\n",
    "            with open(csv_file_path, \"a\", newline=\"\") as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow(\n",
    "                    [\n",
    "                        ds_name,\n",
    "                        model_name,\n",
    "                        res[\"MSE[mean]\"][0],\n",
    "                        res[\"MSE[0.5]\"][0],\n",
    "                        res[\"MAE[0.5]\"][0],\n",
    "                        res[\"MASE[0.5]\"][0],\n",
    "                        res[\"MAPE[0.5]\"][0],\n",
    "                        res[\"sMAPE[0.5]\"][0],\n",
    "                        res[\"MSIS\"][0],\n",
    "                        res[\"RMSE[mean]\"][0],\n",
    "                        res[\"NRMSE[mean]\"][0],\n",
    "                        res[\"ND[0.5]\"][0],\n",
    "                        res[\"mean_weighted_sum_quantile_loss\"][0],\n",
    "                        ds_name,\n",
    "                        dataset_properties_map[ds_name][\"num_variates\"],\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        print(f\"Results for {ds_name} have been written to {csv_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

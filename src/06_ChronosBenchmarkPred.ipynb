{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1841c0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gluonts in c:\\users\\giuli\\anaconda3\\lib\\site-packages (0.16.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\giuli\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\giuli\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\giuli\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy<2.2,>=1.16 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from gluonts) (2.1.3)\n",
      "Requirement already satisfied: pandas<3,>=1.0 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from gluonts) (2.2.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.7 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from gluonts) (2.11.4)\n",
      "Requirement already satisfied: tqdm~=4.23 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from gluonts) (4.67.1)\n",
      "Requirement already satisfied: toolz~=0.10 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from gluonts) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from gluonts) (4.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from pandas<3,>=1.0->gluonts) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from pandas<3,>=1.0->gluonts) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from pandas<3,>=1.0->gluonts) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.7->gluonts) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.7->gluonts) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.7->gluonts) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from tqdm~=4.23->gluonts) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.0->gluonts) (1.16.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\giuli\\anaconda3\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from datasets) (0.31.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from datasets) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\giuli\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\giuli\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\giuli\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: utilsforecast in c:\\users\\giuli\\anaconda3\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: numpy in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from utilsforecast) (2.1.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from utilsforecast) (22.0)\n",
      "Requirement already satisfied: pandas>=1.1.1 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from utilsforecast) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from pandas>=1.1.1->utilsforecast) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from pandas>=1.1.1->utilsforecast) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from pandas>=1.1.1->utilsforecast) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\giuli\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1.1->utilsforecast) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\giuli\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\giuli\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\giuli\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install gluonts\n",
    "!pip install --upgrade datasets\n",
    "!pip install utilsforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f18cff76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Documenti\\VS_Code\\tesi\\TSFM-ZeroShotEval\\src\\TSFM-ZeroShotEval\\src\\TSFM-ZeroShotEval\\src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'TSFM-ZeroShotEval'...\n",
      "Updating files:  48% (73/151)\n",
      "Updating files:  49% (74/151)\n",
      "Updating files:  50% (76/151)\n",
      "Updating files:  51% (78/151)\n",
      "Updating files:  52% (79/151)\n",
      "Updating files:  53% (81/151)\n",
      "Updating files:  54% (82/151)\n",
      "Updating files:  55% (84/151)\n",
      "Updating files:  56% (85/151)\n",
      "Updating files:  57% (87/151)\n",
      "Updating files:  58% (88/151)\n",
      "Updating files:  59% (90/151)\n",
      "Updating files:  60% (91/151)\n",
      "Updating files:  61% (93/151)\n",
      "Updating files:  62% (94/151)\n",
      "Updating files:  63% (96/151)\n",
      "Updating files:  64% (97/151)\n",
      "Updating files:  65% (99/151)\n",
      "Updating files:  66% (100/151)\n",
      "Updating files:  67% (102/151)\n",
      "Updating files:  68% (103/151)\n",
      "Updating files:  69% (105/151)\n",
      "Updating files:  70% (106/151)\n",
      "Updating files:  71% (108/151)\n",
      "Updating files:  72% (109/151)\n",
      "Updating files:  73% (111/151)\n",
      "Updating files:  74% (112/151)\n",
      "Updating files:  75% (114/151)\n",
      "Updating files:  76% (115/151)\n",
      "Updating files:  77% (117/151)\n",
      "Updating files:  78% (118/151)\n",
      "Updating files:  79% (120/151)\n",
      "Updating files:  80% (121/151)\n",
      "Updating files:  81% (123/151)\n",
      "Updating files:  82% (124/151)\n",
      "Updating files:  83% (126/151)\n",
      "Updating files:  84% (127/151)\n",
      "Updating files:  85% (129/151)\n",
      "Updating files:  86% (130/151)\n",
      "Updating files:  87% (132/151)\n",
      "Updating files:  88% (133/151)\n",
      "Updating files:  89% (135/151)\n",
      "Updating files:  90% (136/151)\n",
      "Updating files:  91% (138/151)\n",
      "Updating files:  92% (139/151)\n",
      "Updating files:  93% (141/151)\n",
      "Updating files:  94% (142/151)\n",
      "Updating files:  95% (144/151)\n",
      "Updating files:  96% (145/151)\n",
      "Updating files:  97% (147/151)\n",
      "Updating files:  98% (148/151)\n",
      "Updating files:  99% (150/151)\n",
      "Updating files: 100% (151/151)\n",
      "Updating files: 100% (151/151), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/GiuliaGhisolfi/TSFM-ZeroShotEval\n",
    "%cd TSFM-ZeroShotEval/src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eba777",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af26ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/chronos_data_proprieties.json\") as f:\n",
    "    dataset_properties_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf66515",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CHRONOS = [\"exchange_rate\", \"ercot\", \"dominick\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcef99e",
   "metadata": {},
   "source": [
    "### Results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b968571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = \"results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the path for the CSV file\n",
    "csv_file_path = os.path.join(output_dir, \"chronos_data_results.csv\")\n",
    "\n",
    "with open(csv_file_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writerow(\n",
    "        [\n",
    "            \"dataset\",\n",
    "            \"model\",\n",
    "            \"eval_metrics/MSE[mean]\",\n",
    "            \"eval_metrics/MSE[0.5]\",\n",
    "            \"eval_metrics/MAE[0.5]\",\n",
    "            \"eval_metrics/MASE[0.5]\",\n",
    "            \"eval_metrics/MAPE[0.5]\",\n",
    "            \"eval_metrics/sMAPE[0.5]\",\n",
    "            \"eval_metrics/MSIS\",\n",
    "            \"eval_metrics/RMSE[mean]\",\n",
    "            \"eval_metrics/NRMSE[mean]\",\n",
    "            \"eval_metrics/ND[0.5]\",\n",
    "            \"eval_metrics/mean_weighted_sum_quantile_loss\",\n",
    "            \"domain\",\n",
    "            \"num_variates\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f589b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec22642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.ev.metrics import (\n",
    "    MSE,\n",
    "    MAE,\n",
    "    MASE,\n",
    "    MAPE,\n",
    "    SMAPE,\n",
    "    MSIS,\n",
    "    RMSE,\n",
    "    NRMSE,\n",
    "    ND,\n",
    "    MeanWeightedSumQuantileLoss,\n",
    ")\n",
    "\n",
    "# Instantiate the metrics\n",
    "metrics = [\n",
    "    MSE(forecast_type=\"mean\"),\n",
    "    MSE(forecast_type=0.5),\n",
    "    MAE(),\n",
    "    MASE(),\n",
    "    MAPE(),\n",
    "    SMAPE(),\n",
    "    MSIS(),\n",
    "    RMSE(),\n",
    "    NRMSE(),\n",
    "    ND(),\n",
    "    MeanWeightedSumQuantileLoss(\n",
    "        quantile_levels=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f18dcf",
   "metadata": {},
   "source": [
    "### Chronos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2e86c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"chronos_bolt_small\" # TODO: change to \"chronos_t5_base\" for the original Chronos model\n",
    "\n",
    "model_path=\"amazon/chronos-bolt-small\"\n",
    "# TODO: use \"amazon/chronos-t5-base\" for the corresponding original Chronos model\n",
    "# \"amazon/chronos-bolt-tiny\", \"amazon/chronos-bolt-mini\", \"amazon/chronos-bolt-small\", \"amazon/chronos-bolt-base\",\n",
    "# \"amazon/chronos-t5-tiny\", \"amazon/chronos-t5-mini\", \"amazon/chronos-t5-small\",\n",
    "# \"amazon/chronos-t5-base\", \"amazon/chronos-t5-large\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5befed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.chronos_predictor import ChronosPredictor\n",
    "from gluonts.model import evaluate_model\n",
    "from gluonts.time_feature import get_seasonality\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "for ds_name in [DATASET_CHRONOS[0]]:\n",
    "        print(f\"Processing dataset: {ds_name}\")\n",
    "        terms = [\"short\", \"medium\", \"long\"]\n",
    "        for term in terms:\n",
    "            ds_config = f\"{ds_name}/{term}\"\n",
    "\n",
    "            ########################################################################################\n",
    "            import pandas as pd\n",
    "            import numpy as np\n",
    "            from gluonts.dataset.split import TestData, OffsetSplitter\n",
    "            from gluonts.dataset.common import ListDataset, FieldName\n",
    "\n",
    "            df = pd.read_parquet(\"data/chronos_benchmark/exchange_rate.arrow\")\n",
    "            dataset_gluonts = ListDataset(\n",
    "                [\n",
    "                    {\n",
    "                        FieldName.ITEM_ID: index,\n",
    "                        FieldName.START: pd.Timestamp(row['start']),\n",
    "                        FieldName.TARGET: np.asarray(row['target'], dtype=np.float32)\n",
    "                    }\n",
    "                    for index, row in df.iterrows()\n",
    "                ],\n",
    "                freq=\"D\" #dataset_properties_map[ds_name][\"freq\"]\n",
    "            )\n",
    "            dataset = TestData( # TODO: change\n",
    "                dataset=dataset_gluonts,\n",
    "                splitter=OffsetSplitter(offset=-8),\n",
    "                prediction_length=8,\n",
    "                windows=15,\n",
    "                distance=None,\n",
    "                max_history=None\n",
    "            )\n",
    "            ########################################################################################\n",
    "\n",
    "            season_length = get_seasonality(dataset_properties_map[ds_name][\"freq\"])\n",
    "            prediction_length = dataset_properties_map[ds_name][\"prediction_lengths\"]\n",
    "\n",
    "            predictor = ChronosPredictor(\n",
    "                model_path=model_path,\n",
    "                num_samples=20,\n",
    "                prediction_length=prediction_length,\n",
    "                # Change device_map to \"cpu\" to run on CPU or \"cuda\" to run on GPU\n",
    "                device_map=\"cuda\",\n",
    "            )\n",
    "\n",
    "            res = evaluate_model(\n",
    "                predictor,\n",
    "                test_data=dataset,\n",
    "                metrics=metrics,\n",
    "                batch_size=512,\n",
    "                axis=None,\n",
    "                mask_invalid_label=True,\n",
    "                allow_nan_forecast=False,\n",
    "                seasonality=season_length,\n",
    "            )\n",
    "\n",
    "            # Append the results to the CSV file\n",
    "            with open(csv_file_path, \"a\", newline=\"\") as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow(\n",
    "                    [\n",
    "                        ds_name,\n",
    "                        model_name,\n",
    "                        res[\"MSE[mean]\"][0],\n",
    "                        res[\"MSE[0.5]\"][0],\n",
    "                        res[\"MAE[0.5]\"][0],\n",
    "                        res[\"MASE[0.5]\"][0],\n",
    "                        res[\"MAPE[0.5]\"][0],\n",
    "                        res[\"sMAPE[0.5]\"][0],\n",
    "                        res[\"MSIS\"][0],\n",
    "                        res[\"RMSE[mean]\"][0],\n",
    "                        res[\"NRMSE[mean]\"][0],\n",
    "                        res[\"ND[0.5]\"][0],\n",
    "                        res[\"mean_weighted_sum_quantile_loss\"][0],\n",
    "                        ds_name,\n",
    "                        dataset_properties_map[ds_name][\"num_variates\"],\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        print(f\"Results for {ds_name} have been written to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c30389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData(dataset=[{'item_id': 0, 'start': Period('1990-01-01', 'D'), 'target': array([0.7855  , 0.7818  , 0.7867  , ..., 0.723197, 0.720825, 0.720825],\n",
       "      dtype=float32)}, {'item_id': 1, 'start': Period('1990-01-01', 'D'), 'target': array([1.611   , 1.61    , 1.6293  , ..., 1.234111, 1.233905, 1.233905],\n",
       "      dtype=float32)}, {'item_id': 2, 'start': Period('1990-01-01', 'D'), 'target': array([0.861698, 0.861104, 0.86103 , ..., 0.745184, 0.744131, 0.744131],\n",
       "      dtype=float32)}, {'item_id': 3, 'start': Period('1990-01-01', 'D'), 'target': array([0.634196, 0.633513, 0.648508, ..., 0.984446, 0.980344, 0.980344],\n",
       "      dtype=float32)}, {'item_id': 4, 'start': Period('1990-01-01', 'D'), 'target': array([0.211242, 0.211242, 0.211242, ..., 0.143997, 0.143993, 0.143993],\n",
       "      dtype=float32)}, {'item_id': 5, 'start': Period('1990-01-01', 'D'), 'target': array([0.006838, 0.006863, 0.006975, ..., 0.008562, 0.008555, 0.008555],\n",
       "      dtype=float32)}, {'item_id': 6, 'start': Period('1990-01-01', 'D'), 'target': array([0.593   , 0.594   , 0.5973  , ..., 0.695943, 0.692689, 0.692689],\n",
       "      dtype=float32)}, {'item_id': 7, 'start': Period('1990-01-01', 'D'), 'target': array([0.525486, 0.523972, 0.526316, ..., 0.691419, 0.690942, 0.690942],\n",
       "      dtype=float32)}], splitter=OffsetSplitter(offset=-8), prediction_length=8, windows=15, distance=None, max_history=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: delete\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gluonts.dataset.split import TestData, OffsetSplitter\n",
    "from gluonts.dataset.common import ListDataset, FieldName\n",
    "\n",
    "df = pd.read_parquet(\"data/chronos_benchmark/exchange_rate.arrow\")\n",
    "dataset_gluonts = ListDataset(\n",
    "    [\n",
    "        {\n",
    "            FieldName.ITEM_ID: index,\n",
    "            FieldName.START: pd.Timestamp(row['start']),\n",
    "            FieldName.TARGET: np.asarray(row['target'], dtype=np.float32)\n",
    "        }\n",
    "        for index, row in df.iterrows()\n",
    "    ],\n",
    "    freq=\"D\" #dataset_properties_map[ds_name][\"freq\"]\n",
    ")\n",
    "dataset = TestData( # TODO: change\n",
    "    dataset=dataset_gluonts,\n",
    "    splitter=OffsetSplitter(offset=-8),\n",
    "    prediction_length=8,\n",
    "    windows=15,\n",
    "    distance=None,\n",
    "    max_history=None\n",
    ")\n",
    "\n",
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
